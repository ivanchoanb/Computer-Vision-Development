{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd4268b2",
   "metadata": {},
   "source": [
    "# **Segmentation Pre-trained YOLO MODEL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1ef94d",
   "metadata": {},
   "source": [
    "Image segmentation with YOLO represents one of the most advanced techniques in computer vision, allowing specific objects to be identified and delimited in real time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997d66d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file  \n",
      "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\AlexisBenitez\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "# !pip install ultralytics (Don't forget install it)\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dcd5c3",
   "metadata": {},
   "source": [
    "For segmentation, we'll use YOLOv11 in its \"nano\" version, which is the smallest model available. This choice is ideal when working with CPUs instead of GPUs, as it requires fewer computational resources.\n",
    "\n",
    "#### You can check https://docs.ultralytics.com/es/tasks/segment/ for other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe85e27",
   "metadata": {},
   "source": [
    "Un aspecto importante al trabajar con segmentación en tiempo real es medir la latencia, es decir, cuánto tiempo tarda el sistema en procesar cada frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee1f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 345.6ms\n",
      "Speed: 52.2ms preprocess, 345.6ms inference, 50.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.4ms\n",
      "Speed: 3.8ms preprocess, 114.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 130.2ms\n",
      "Speed: 2.2ms preprocess, 130.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.3ms\n",
      "Speed: 4.7ms preprocess, 125.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.4ms\n",
      "Speed: 1.9ms preprocess, 118.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.8ms\n",
      "Speed: 2.3ms preprocess, 97.8ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.7ms\n",
      "Speed: 2.2ms preprocess, 103.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.3ms\n",
      "Speed: 2.6ms preprocess, 99.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.1ms\n",
      "Speed: 2.3ms preprocess, 104.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.2ms\n",
      "Speed: 2.1ms preprocess, 114.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.9ms\n",
      "Speed: 2.2ms preprocess, 103.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.8ms\n",
      "Speed: 2.1ms preprocess, 102.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.9ms\n",
      "Speed: 1.8ms preprocess, 98.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.6ms\n",
      "Speed: 2.3ms preprocess, 110.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.7ms\n",
      "Speed: 2.0ms preprocess, 117.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.3ms\n",
      "Speed: 2.9ms preprocess, 94.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.6ms\n",
      "Speed: 2.5ms preprocess, 100.6ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.4ms\n",
      "Speed: 2.3ms preprocess, 96.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 102.1ms\n",
      "Speed: 2.3ms preprocess, 102.1ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.8ms\n",
      "Speed: 2.6ms preprocess, 88.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.3ms\n",
      "Speed: 2.1ms preprocess, 99.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.5ms\n",
      "Speed: 3.2ms preprocess, 107.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.8ms\n",
      "Speed: 2.8ms preprocess, 100.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.5ms\n",
      "Speed: 2.0ms preprocess, 93.5ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.2ms\n",
      "Speed: 3.0ms preprocess, 85.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 81.2ms\n",
      "Speed: 2.5ms preprocess, 81.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.4ms\n",
      "Speed: 3.0ms preprocess, 79.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 82.9ms\n",
      "Speed: 2.1ms preprocess, 82.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 83.9ms\n",
      "Speed: 1.8ms preprocess, 83.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 75.9ms\n",
      "Speed: 3.6ms preprocess, 75.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 80.6ms\n",
      "Speed: 1.8ms preprocess, 80.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.7ms\n",
      "Speed: 2.0ms preprocess, 83.7ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 75.5ms\n",
      "Speed: 2.3ms preprocess, 75.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.3ms\n",
      "Speed: 2.1ms preprocess, 89.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.9ms\n",
      "Speed: 1.8ms preprocess, 81.9ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.2ms\n",
      "Speed: 2.2ms preprocess, 94.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.9ms\n",
      "Speed: 2.1ms preprocess, 123.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.4ms\n",
      "Speed: 1.8ms preprocess, 81.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.2ms\n",
      "Speed: 1.7ms preprocess, 86.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.4ms\n",
      "Speed: 1.9ms preprocess, 100.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.3ms\n",
      "Speed: 1.6ms preprocess, 77.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.9ms\n",
      "Speed: 1.7ms preprocess, 88.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.7ms\n",
      "Speed: 2.3ms preprocess, 110.7ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.9ms\n",
      "Speed: 2.6ms preprocess, 106.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.4ms\n",
      "Speed: 2.3ms preprocess, 98.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.0ms\n",
      "Speed: 3.2ms preprocess, 79.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.2ms\n",
      "Speed: 1.6ms preprocess, 105.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.0ms\n",
      "Speed: 1.7ms preprocess, 83.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 77.0ms\n",
      "Speed: 2.4ms preprocess, 77.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.3ms\n",
      "Speed: 2.4ms preprocess, 79.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.6ms\n",
      "Speed: 1.7ms preprocess, 83.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 79.1ms\n",
      "Speed: 1.6ms preprocess, 79.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 1.7ms preprocess, 80.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 1.9ms preprocess, 81.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 2.0ms preprocess, 83.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.9ms\n",
      "Speed: 2.1ms preprocess, 84.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.0ms\n",
      "Speed: 3.1ms preprocess, 82.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 80.6ms\n",
      "Speed: 1.8ms preprocess, 80.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 78.1ms\n",
      "Speed: 1.9ms preprocess, 78.1ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.1ms\n",
      "Speed: 3.1ms preprocess, 79.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.0ms\n",
      "Speed: 1.7ms preprocess, 79.0ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.1ms\n",
      "Speed: 1.7ms preprocess, 83.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 82.1ms\n",
      "Speed: 2.0ms preprocess, 82.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 85.1ms\n",
      "Speed: 1.8ms preprocess, 85.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.8ms\n",
      "Speed: 1.6ms preprocess, 82.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.9ms\n",
      "Speed: 2.3ms preprocess, 83.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 81.1ms\n",
      "Speed: 1.7ms preprocess, 81.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 1.8ms preprocess, 88.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 78.4ms\n",
      "Speed: 1.9ms preprocess, 78.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.9ms\n",
      "Speed: 1.9ms preprocess, 82.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 79.8ms\n",
      "Speed: 3.0ms preprocess, 79.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 84.8ms\n",
      "Speed: 3.5ms preprocess, 84.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.9ms\n",
      "Speed: 1.9ms preprocess, 88.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 98.4ms\n",
      "Speed: 2.3ms preprocess, 98.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.3ms\n",
      "Speed: 2.2ms preprocess, 110.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 112.1ms\n",
      "Speed: 3.6ms preprocess, 112.1ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 97.4ms\n",
      "Speed: 2.6ms preprocess, 97.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 82.2ms\n",
      "Speed: 1.8ms preprocess, 82.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 82.8ms\n",
      "Speed: 1.9ms preprocess, 82.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 81.8ms\n",
      "Speed: 2.9ms preprocess, 81.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.4ms\n",
      "Speed: 1.7ms preprocess, 78.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 2.0ms preprocess, 84.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 1.7ms preprocess, 83.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 74.4ms\n",
      "Speed: 2.2ms preprocess, 74.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.1ms\n",
      "Speed: 1.7ms preprocess, 110.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.1ms\n",
      "Speed: 1.9ms preprocess, 79.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 2.2ms preprocess, 80.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 74.6ms\n",
      "Speed: 1.9ms preprocess, 74.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.4ms\n",
      "Speed: 1.9ms preprocess, 87.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.3ms\n",
      "Speed: 2.0ms preprocess, 84.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.5ms\n",
      "Speed: 1.9ms preprocess, 102.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.5ms\n",
      "Speed: 2.0ms preprocess, 85.5ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.1ms\n",
      "Speed: 3.8ms preprocess, 81.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.6ms\n",
      "Speed: 1.9ms preprocess, 84.6ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.1ms\n",
      "Speed: 1.8ms preprocess, 80.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 81.2ms\n",
      "Speed: 1.6ms preprocess, 81.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.5ms\n",
      "Speed: 1.9ms preprocess, 81.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.6ms\n",
      "Speed: 2.2ms preprocess, 85.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.5ms\n",
      "Speed: 1.6ms preprocess, 85.5ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 113.9ms\n",
      "Speed: 3.1ms preprocess, 113.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.7ms\n",
      "Speed: 3.1ms preprocess, 106.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.1ms\n",
      "Speed: 1.5ms preprocess, 82.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.5ms\n",
      "Speed: 1.8ms preprocess, 81.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.2ms\n",
      "Speed: 1.9ms preprocess, 80.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.4ms\n",
      "Speed: 1.9ms preprocess, 85.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.8ms\n",
      "Speed: 1.5ms preprocess, 83.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.2ms\n",
      "Speed: 1.6ms preprocess, 80.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.6ms\n",
      "Speed: 1.8ms preprocess, 83.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.3ms\n",
      "Speed: 1.6ms preprocess, 82.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.1ms\n",
      "Speed: 1.9ms preprocess, 86.1ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.9ms\n",
      "Speed: 1.6ms preprocess, 82.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.8ms\n",
      "Speed: 1.8ms preprocess, 84.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 76.3ms\n",
      "Speed: 1.5ms preprocess, 76.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 80.5ms\n",
      "Speed: 2.8ms preprocess, 80.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 84.3ms\n",
      "Speed: 1.6ms preprocess, 84.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.0ms\n",
      "Speed: 1.6ms preprocess, 84.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 79.3ms\n",
      "Speed: 2.1ms preprocess, 79.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.5ms\n",
      "Speed: 1.6ms preprocess, 82.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 80.4ms\n",
      "Speed: 1.7ms preprocess, 80.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.9ms\n",
      "Speed: 2.0ms preprocess, 121.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.8ms\n",
      "Speed: 1.7ms preprocess, 102.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.9ms\n",
      "Speed: 1.7ms preprocess, 80.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 cell phone, 85.1ms\n",
      "Speed: 1.6ms preprocess, 85.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.7ms\n",
      "Speed: 1.6ms preprocess, 80.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.1ms\n",
      "Speed: 1.9ms preprocess, 84.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.8ms\n",
      "Speed: 1.6ms preprocess, 81.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 84.1ms\n",
      "Speed: 1.6ms preprocess, 84.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 78.5ms\n",
      "Speed: 1.7ms preprocess, 78.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 73.4ms\n",
      "Speed: 2.3ms preprocess, 73.4ms inference, 0.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.2ms\n",
      "Speed: 2.4ms preprocess, 107.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.7ms\n",
      "Speed: 2.9ms preprocess, 107.7ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.7ms\n",
      "Speed: 2.7ms preprocess, 103.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 84.5ms\n",
      "Speed: 1.7ms preprocess, 84.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 85.0ms\n",
      "Speed: 1.8ms preprocess, 85.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 78.5ms\n",
      "Speed: 3.4ms preprocess, 78.5ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 84.6ms\n",
      "Speed: 1.8ms preprocess, 84.6ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.8ms\n",
      "Speed: 2.7ms preprocess, 91.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.8ms\n",
      "Speed: 2.2ms preprocess, 91.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.4ms\n",
      "Speed: 2.6ms preprocess, 97.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 122.4ms\n",
      "Speed: 3.4ms preprocess, 122.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 150.5ms\n",
      "Speed: 2.4ms preprocess, 150.5ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 106.9ms\n",
      "Speed: 3.5ms preprocess, 106.9ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 91.5ms\n",
      "Speed: 3.0ms preprocess, 91.5ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 97.3ms\n",
      "Speed: 2.5ms preprocess, 97.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 96.7ms\n",
      "Speed: 2.6ms preprocess, 96.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.3ms\n",
      "Speed: 2.0ms preprocess, 99.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 121.8ms\n",
      "Speed: 3.7ms preprocess, 121.8ms inference, 5.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.9ms\n",
      "Speed: 2.7ms preprocess, 114.9ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 100.5ms\n",
      "Speed: 2.5ms preprocess, 100.5ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 92.0ms\n",
      "Speed: 2.1ms preprocess, 92.0ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.4ms\n",
      "Speed: 2.0ms preprocess, 95.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 116.6ms\n",
      "Speed: 2.1ms preprocess, 116.6ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 135.2ms\n",
      "Speed: 2.0ms preprocess, 135.2ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 112.3ms\n",
      "Speed: 2.3ms preprocess, 112.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 96.1ms\n",
      "Speed: 2.0ms preprocess, 96.1ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.6ms\n",
      "Speed: 3.0ms preprocess, 93.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.9ms\n",
      "Speed: 1.8ms preprocess, 116.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 1 cell phone, 97.2ms\n",
      "Speed: 2.3ms preprocess, 97.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.5ms\n",
      "Speed: 2.2ms preprocess, 126.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.8ms\n",
      "Speed: 3.2ms preprocess, 132.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 177.1ms\n",
      "Speed: 3.4ms preprocess, 177.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.9ms\n",
      "Speed: 2.5ms preprocess, 114.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 101.4ms\n",
      "Speed: 2.3ms preprocess, 101.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.8ms\n",
      "Speed: 3.3ms preprocess, 100.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.8ms\n",
      "Speed: 2.0ms preprocess, 97.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.4ms\n",
      "Speed: 3.1ms preprocess, 94.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 95.2ms\n",
      "Speed: 2.0ms preprocess, 95.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.9ms\n",
      "Speed: 2.3ms preprocess, 102.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.4ms\n",
      "Speed: 2.0ms preprocess, 99.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.7ms\n",
      "Speed: 2.5ms preprocess, 105.7ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 127.3ms\n",
      "Speed: 2.3ms preprocess, 127.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.3ms\n",
      "Speed: 2.5ms preprocess, 115.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.0ms\n",
      "Speed: 2.2ms preprocess, 111.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.3ms\n",
      "Speed: 2.5ms preprocess, 96.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.0ms\n",
      "Speed: 2.2ms preprocess, 98.0ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 97.0ms\n",
      "Speed: 2.6ms preprocess, 97.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.4ms\n",
      "Speed: 2.3ms preprocess, 105.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 121.9ms\n",
      "Speed: 3.1ms preprocess, 121.9ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.2ms\n",
      "Speed: 2.2ms preprocess, 115.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 125.0ms\n",
      "Speed: 2.2ms preprocess, 125.0ms inference, 5.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.5ms\n",
      "Speed: 3.0ms preprocess, 107.5ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.6ms\n",
      "Speed: 2.5ms preprocess, 118.6ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.9ms\n",
      "Speed: 2.3ms preprocess, 118.9ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.7ms\n",
      "Speed: 2.1ms preprocess, 104.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 119.8ms\n",
      "Speed: 2.3ms preprocess, 119.8ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 149.9ms\n",
      "Speed: 2.9ms preprocess, 149.9ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 140.0ms\n",
      "Speed: 3.5ms preprocess, 140.0ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 371.8ms\n",
      "Speed: 4.8ms preprocess, 371.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 124.6ms\n",
      "Speed: 2.8ms preprocess, 124.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.5ms\n",
      "Speed: 2.5ms preprocess, 112.5ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.9ms\n",
      "Speed: 3.4ms preprocess, 107.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.9ms\n",
      "Speed: 2.2ms preprocess, 107.9ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 100.4ms\n",
      "Speed: 2.1ms preprocess, 100.4ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 99.9ms\n",
      "Speed: 2.7ms preprocess, 99.9ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.2ms\n",
      "Speed: 2.6ms preprocess, 105.2ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.8ms\n",
      "Speed: 4.3ms preprocess, 104.8ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.5ms\n",
      "Speed: 2.0ms preprocess, 110.5ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 134.2ms\n",
      "Speed: 2.6ms preprocess, 134.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 167.0ms\n",
      "Speed: 25.5ms preprocess, 167.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 167.4ms\n",
      "Speed: 2.7ms preprocess, 167.4ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 123.0ms\n",
      "Speed: 4.2ms preprocess, 123.0ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.8ms\n",
      "Speed: 2.9ms preprocess, 104.8ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.3ms\n",
      "Speed: 3.3ms preprocess, 112.3ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.3ms\n",
      "Speed: 2.8ms preprocess, 112.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 107.3ms\n",
      "Speed: 2.4ms preprocess, 107.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 119.8ms\n",
      "Speed: 2.7ms preprocess, 119.8ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 106.8ms\n",
      "Speed: 3.0ms preprocess, 106.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 102.3ms\n",
      "Speed: 14.3ms preprocess, 102.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 98.8ms\n",
      "Speed: 2.2ms preprocess, 98.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 120.4ms\n",
      "Speed: 3.0ms preprocess, 120.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 114.8ms\n",
      "Speed: 2.5ms preprocess, 114.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 104.8ms\n",
      "Speed: 4.2ms preprocess, 104.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "#Load the model YOLOv11 for segmentation (or have download 'yolo11n-seg.pt')\n",
    "\n",
    "\n",
    "model = YOLO(\"yolo11n-seg\")\n",
    "\n",
    "# Define the source of video (Can be the path o index of cam )\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # To measure time of processing to calculate the latency \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Make the detecation and detection on the frame \n",
    "    results = model(\n",
    "        frame, \n",
    "        conf=0.7, # Confidence of show over 70 %\n",
    "        #classes=[0] # \"0\" for focuss just in person and comment if you wanna detect all categories in the COCO clases.txt of nano model\n",
    "        )\n",
    "    latency = (time.time() - start_time) * 1000  # miliseconds in latency\n",
    "\n",
    "    # Acces to adress (bounding boxes)\n",
    "    boxes_obj = results[0].boxes\n",
    "    if boxes_obj is not None and len(boxes_obj) > 0:\n",
    "        bboxes = boxes_obj.xyxy.cpu().numpy()   # [x1, y1, x2, y2]\n",
    "        confs = boxes_obj.conf.cpu().numpy()      # Confidence scores (Puntajes de confianza)\n",
    "        classes = boxes_obj.cls.cpu().numpy()     # Class index (Índices de clase)\n",
    "        \n",
    "        for i, box in enumerate(bboxes):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            \n",
    "            # Get the class name if this exist \n",
    "            class_name = model.names[int(classes[i])] if hasattr(model, 'names') else str(int(classes[i]))\n",
    "            label = f'{class_name} {confs[i]:.2f}'\n",
    "            # Draw bounding box and label the frame \n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    # PProcess the segmetations: assing random color for every mask detected\n",
    "    masks_obj = results[0].masks\n",
    "    if masks_obj is not None and len(masks_obj) > 0:\n",
    "        # Extract the mask: It's assume that masks_obj.data is a tensor\n",
    "        masks = masks_obj.data.cpu().numpy() if hasattr(masks_obj.data, 'cpu') else masks_obj.data\n",
    "        for mask in masks:\n",
    "            # Become the mask to binary (umbral 0.5) and scale to 0-255\n",
    "            mask_bin = (mask > 0.5).astype(np.uint8) * 255\n",
    "            # Reshape the mask for get the same size in frame \n",
    "            mask_bin = cv2.resize(mask_bin, (frame.shape[1], frame.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "            \n",
    "            # Create a boolean mask with 3 channels \n",
    "            binary_mask = cv2.threshold(mask_bin, 127, 255, cv2.THRESH_BINARY)[1]\n",
    "            binary_mask_3c = cv2.merge([binary_mask, binary_mask, binary_mask])\n",
    "            \n",
    "            # Generate radom color  (BGR)\n",
    "            random_color = np.random.randint(0, 256, size=(3,), dtype=np.uint8)\n",
    "            # Create an image the same size as the frame, filled with the random color\n",
    "            colored_mask = np.full((frame.shape[0], frame.shape[1], 3), random_color, dtype=np.uint8)\n",
    "            \n",
    "            # Combine mask with frame: In regions where the mask is 255, the random color is used\n",
    "            output_frame = frame.copy()\n",
    "            output_frame[binary_mask_3c == 255] = colored_mask[binary_mask_3c == 255]\n",
    "            \n",
    "            # Update the frame with the colored mask (keeping the natural background)\n",
    "            frame = output_frame\n",
    "        \n",
    "        # Display the number of masks detected\n",
    "        cv2.putText(frame, f'Masks: {len(masks)}', (10, 70),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Display latency in the frame\n",
    "    cv2.putText(frame, f'Latency: {latency:.1f}ms', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "    # Display the processed frame in real time\n",
    "    cv2.imshow(\"YOLOv11-Seg - Real Time segementation\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5516a0",
   "metadata": {},
   "source": [
    "#### Important facts \n",
    "    - YOLO comes pre-trained to detect 80 different object categories. We can filter to show only the classes we're interested in\n",
    "\n",
    "    - We can set a confidence threshold to show only detections with high probability (Could be 0.7 or 70% )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee05c3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04169d05",
   "metadata": {},
   "source": [
    "### Real-Time Segmentation and Heatmap Generation Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a706c2",
   "metadata": {},
   "source": [
    "The implemented solution combines two powerful techniques:\n",
    "\n",
    "- Motion detection: Using background subtraction to identify any changes between frames.\n",
    "- YOLO segmentation: Applying a specific model to identify and isolate only people.\n",
    "\n",
    "The result is a refined hitmap that exclusively shows the movement of people, eliminating false positives and providing much cleaner and more useful data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc443869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies \n",
    "# !pip install ultralytics\n",
    "\n",
    "# Libraries requiered \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25c0df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\AlexisBenitez\\AppData\\Local\\Temp\\ipykernel_26884\\1619202870.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  video_path = \"Video Useful\\park_detection.avi\"\n"
     ]
    }
   ],
   "source": [
    "# video_path = \"Video Useful\\store-aisle-detection.mp4\"\n",
    "video_path = \"Video Useful\\park_detection.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f75b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "    history=500,          # Number of frames useed for build the background \n",
    "    varThreshold=16,      # Sensibility for detect changues \n",
    "    detectShadows=True,   # Sahdow Detection\n",
    "    )\n",
    "\n",
    "heatmap_refined = None\n",
    "\n",
    "# Load model YOLOv11 for segementation\n",
    "model = YOLO(\"yolo11n-seg\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize the heatmap accumulator on the first frame\n",
    "    if heatmap_refined is None:\n",
    "        heatmap_refined = np.zeros(frame.shape[:2], dtype=np.float32)\n",
    "\n",
    "    # --- Paso 1: Banckgroudn subtraction ---\n",
    "    fgmask = bg_subtractor.apply(frame)\n",
    "    # threshold for get a binary mask clean \n",
    "    _, fgmask = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # --- Step 2: Segmentation with YOLO ---\n",
    "# We perform detection with segmentation on the entire frame.\n",
    "\n",
    "    results = model(frame, verbose=False)[0]\n",
    "\n",
    "    # Create an empty mask to accumulate the segmentations of the \"person\" class\n",
    "    segmentation_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    if results.masks is not None:\n",
    "        # Extract the masks and classes\n",
    "        masks = results.masks.data.cpu().numpy() if hasattr(results.masks.data, 'cpu') else results.masks.data\n",
    "        classes = results.boxes.cls.cpu().numpy() if hasattr(results.boxes.cls, 'cpu') else results.boxes.cls\n",
    "\n",
    "        for mask, cls in zip(masks, classes):\n",
    "            if int(cls) == 0:  # We filter person detections (in COCO, \"person\" is class 0)\n",
    "                mask_bin = (mask > 0.5).astype(np.uint8) * 255\n",
    "                # Resize mask_bin to the dimensions of the frame (or segmentation_mask)\n",
    "                mask_bin_resized = cv2.resize(mask_bin, (segmentation_mask.shape[1], segmentation_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "                segmentation_mask = cv2.bitwise_or(segmentation_mask, mask_bin_resized)\n",
    "\n",
    "# --- Step 3: Mask Combination ---\n",
    "# An intersection is performed between the motion mask and the person segmentation mask\n",
    "    refined_mask = cv2.bitwise_and(fgmask, segmentation_mask)\n",
    "\n",
    "    # We accumulate the refined mask on the heatmap\n",
    "    heatmap_refined = cv2.add(heatmap_refined, refined_mask.astype(np.float32))\n",
    "\n",
    "    # intermedia Visualization\n",
    "    cv2.imshow(\"Original Frame\", frame)\n",
    "    cv2.imshow(\"Movement Mask(FG)\", fgmask)\n",
    "    cv2.imshow(\"Segmentation Mask (Persons)\", segmentation_mask)\n",
    "    cv2.imshow(\"Refined Mask\", refined_mask)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c8fc86",
   "metadata": {},
   "source": [
    "### What advantages does segmentation offer in traffic analysis?\n",
    "\n",
    "Elimination of false positives: Moving objects other than people (such as ropes, doors, etc.) are no longer detected.\n",
    "\n",
    "Increased accuracy: The resulting hitmap shows only human movement.\n",
    "\n",
    "Cleaner data: The visualization is clearer and easier to interpret.\n",
    "\n",
    "More focused analysis: Allows you to focus on customer behavior without distractions.\n",
    "\n",
    "\n",
    "For deploy and implement in google colab use (!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n-seg.pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd6c4f9",
   "metadata": {},
   "source": [
    "### Here We just create the refined map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6565964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "C:\\Users\\AlexisBenitez\\AppData\\Local\\Temp\\ipykernel_26884\\1619202870.py:2: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  video_path = \"Video Useful\\park_detection.avi\"\n"
     ]
    }
   ],
   "source": [
    "# video_path = \"Video Useful\\store-aisle-detection.mp4\"\n",
    "video_path = \"Video Useful\\park_detection.avi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c708573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries requiered \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f56005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open Video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2(\n",
    "    history=500,          # Number of frames useed for build the background \n",
    "    varThreshold=16,      # Sensibility for detect changues \n",
    "    detectShadows=True,   # Sahdow Detection\n",
    "    )\n",
    "\n",
    "heatmap_refined = None\n",
    "\n",
    "# Load model YOLOv11 for segementation\n",
    "model = YOLO(\"yolo11n-seg\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Initialize the heatmap accumulator on the first frame\n",
    "    if heatmap_refined is None:\n",
    "        heatmap_refined = np.zeros(frame.shape[:2], dtype=np.float32)\n",
    "\n",
    "    # --- step 1: Banckgroudn subtraction ---\n",
    "    fgmask = bg_subtractor.apply(frame)\n",
    "    # threshold for get a binary mask clean \n",
    "    _, fgmask = cv2.threshold(fgmask, 200, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # --- Step 2: Segmentation with YOLO ---\n",
    "# We perform detection with segmentation on the entire frame.\n",
    "\n",
    "    results = model(frame, verbose=False)[0]\n",
    "\n",
    "    # Create an empty mask to accumulate the segmentations of the \"person\" class\n",
    "    segmentation_mask = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    if results.masks is not None:\n",
    "        # Extract the masks and classes\n",
    "        masks = results.masks.data.cpu().numpy() if hasattr(results.masks.data, 'cpu') else results.masks.data\n",
    "        classes = results.boxes.cls.cpu().numpy() if hasattr(results.boxes.cls, 'cpu') else results.boxes.cls\n",
    "\n",
    "        for mask, cls in zip(masks, classes):\n",
    "            if int(cls) == 0:  # We filter person detections (in COCO, \"person\" is class 0)\n",
    "                mask_bin = (mask > 0.5).astype(np.uint8) * 255\n",
    "                # Resize mask_bin to the dimensions of the frame (or segmentation_mask)\n",
    "                mask_bin_resized = cv2.resize(mask_bin, (segmentation_mask.shape[1], segmentation_mask.shape[0]), interpolation=cv2.INTER_NEAREST)\n",
    "                segmentation_mask = cv2.bitwise_or(segmentation_mask, mask_bin_resized)\n",
    "\n",
    "# --- Step 3: Mask Combination ---\n",
    "# An intersection is performed between the motion mask and the person segmentation mask\n",
    "    refined_mask = cv2.bitwise_and(fgmask, segmentation_mask)\n",
    "\n",
    "    # We accumulate the refined mask on the heatmap\n",
    "    heatmap_refined = cv2.add(heatmap_refined, refined_mask.astype(np.float32))\n",
    "\n",
    "# Show the heat map refined\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(heatmap_refined, cmap=\"hot\")\n",
    "plt.title(\"Heatmap refined with YOLO segementation\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11d8c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the heatmap to range 0-255\n",
    "heatmap_norm = cv2.normalize(heatmap_refined, None, 0, 255, cv2.NORM_MINMAX)\n",
    "heatmap_norm = np.uint8(heatmap_norm)\n",
    "\n",
    "# add a colormap (example, COLORMAP_VIRIDIS)\n",
    "colored_heatmap = cv2.applyColorMap(heatmap_norm, cv2.COLORMAP_VIRIDIS)\n",
    "\n",
    "# Visualization with matplotlib\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(cv2.cvtColor(colored_heatmap, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Normalized Heatmap\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f3717e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
