{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d05ff62",
   "metadata": {},
   "source": [
    "## Mediapipe Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe7b687",
   "metadata": {},
   "source": [
    "MediaPipe is an open-source tool developed by Google that offers various solutions for image and video analysis. Its key features include:\n",
    "\n",
    "-Highly accurate facial point detection.\n",
    "\n",
    "-Real-time body pose recognition.\n",
    "\n",
    "-Highly accurate motion detection.\n",
    "\n",
    "-Large community of developers who constantly contribute.\n",
    "\n",
    "-Official Google support, ensuring continuous updates and improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2b6bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.21-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from mediapipe) (25.2.10)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.6.0-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from mediapipe) (3.9.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from mediapipe) (1.26.4)\n",
      "Collecting opencv-contrib-python (from mediapipe)\n",
      "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from mediapipe) (0.2.0)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
      "Collecting ml_dtypes>=0.5.0 (from jax->mediapipe)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: opt_einsum in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.11.1 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from jax->mediapipe) (1.13.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\alexisbenitez\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\alexisbenitez\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\alexisbenitez\\anaconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\alexisbenitez\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.21-cp312-cp312-win_amd64.whl (51.0 MB)\n",
      "Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Using cached jax-0.6.0-py3-none-any.whl (2.3 MB)\n",
      "Using cached jaxlib-0.6.0-cp312-cp312-win_amd64.whl (56.4 MB)\n",
      "Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-win_amd64.whl (46.2 MB)\n",
      "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Installing collected packages: opencv-contrib-python, ml_dtypes, absl-py, sounddevice, jaxlib, jax, mediapipe\n",
      "Successfully installed absl-py-2.2.2 jax-0.6.0 jaxlib-0.6.0 mediapipe-0.10.21 ml_dtypes-0.5.1 opencv-contrib-python-4.11.0.86 sounddevice-0.5.1\n"
     ]
    }
   ],
   "source": [
    "# Installed Mediapipe \n",
    "# You can find problems installing mediapipe, that why you must use \"!pip install mediapipe --user\"\n",
    "# !pip install mediapipe --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b883babc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03b4f1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose( \n",
    "    min_detection_confidence=0.5, \n",
    "    min_tracking_confidence=0.5,\n",
    "    static_image_mode=False,\n",
    "    )\n",
    "\n",
    "# Initialize landmark drawing\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Capture real-time video from the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert frame to RGB (required by Mediapipe)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process image to get landmarks\n",
    "    results = pose.process(frame_rgb)\n",
    "    \n",
    "    # Draw landmarks on the image if detected\n",
    "    if results.pose_landmarks:\n",
    "        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "    \n",
    "    # Show the frame with landmarks\n",
    "    cv2.imshow('Pose Estimation', frame)\n",
    "    \n",
    "    # Press 'q' to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2236d9e6",
   "metadata": {},
   "source": [
    "## Tracking just with 2 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb670696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe Face Mesh (We focus on the face)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Capture video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resultados = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if resultados.multi_face_landmarks:\n",
    "        for face_landmarks in resultados.multi_face_landmarks:\n",
    "            # Get key points of the eyes\n",
    "            left_eye = face_landmarks.landmark[33]\n",
    "            right_eye = face_landmarks.landmark[263]\n",
    "            \n",
    "            # Convert to absolute coordinates\n",
    "            h, w, _ = frame.shape\n",
    "            left_eye_coords = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "            right_eye_coords = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "\n",
    "            # Draw the eyes on the image\n",
    "            cv2.circle(frame, left_eye_coords, 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, right_eye_coords, 3, (0, 255, 0), -1)\n",
    "\n",
    "    cv2.imshow(\"Face Mesh - Eyes\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d336ef",
   "metadata": {},
   "source": [
    "## EYES Tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24fe3c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Captures video from the webcam, processes each frame using MediaPipe Face Mesh (with refine_landmarks enabled),\n",
    "and draws:\n",
    "    - Eye reference points (in green)\n",
    "    - The 4 landmarks used to estimate the iris center (in red)\n",
    "    - The estimated iris center (in blue)\n",
    "\"\"\"\n",
    "\n",
    "# Initialize MediaPipe Face Mesh with landmark refinement (for iris)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    refine_landmarks=True  # Enables refined detection for the iris\n",
    ")\n",
    "\n",
    "# Initialize video capture from webcam (index 1)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame from BGR to RGB (required format for MediaPipe)\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            # Get frame dimensions to convert normalized coordinates to pixels\n",
    "            h, w, _ = frame.shape\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # Detect eye reference points (landmarks 33 and 263)\n",
    "            # ------------------------------------------------------------\n",
    "            left_eye = face_landmarks.landmark[33]\n",
    "            right_eye = face_landmarks.landmark[263]\n",
    "            left_eye_coords = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "            right_eye_coords = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "\n",
    "            # Draw eye reference points in green\n",
    "            cv2.circle(frame, left_eye_coords, 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, right_eye_coords, 3, (0, 255, 0), -1)\n",
    "\n",
    "            # ------------------------------------------------------------\n",
    "            # Detect the 4 landmarks used to estimate the iris center\n",
    "            # ------------------------------------------------------------\n",
    "\n",
    "            # Left eye iris landmarks: 468, 469, 470, 471\n",
    "            left_iris_points = []\n",
    "            for i in range(468, 468 + 4):\n",
    "                pt = face_landmarks.landmark[i]\n",
    "                x, y = int(pt.x * w), int(pt.y * h)\n",
    "                left_iris_points.append((x, y))\n",
    "                # Draw iris landmarks in red\n",
    "                cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "            # Compute center of the left iris\n",
    "            left_iris_center = (\n",
    "                int(sum([p[0] for p in left_iris_points]) / len(left_iris_points)),\n",
    "                int(sum([p[1] for p in left_iris_points]) / len(left_iris_points))\n",
    "            )\n",
    "\n",
    "            # Right eye iris landmarks: 473, 474, 475, 476\n",
    "            right_iris_points = []\n",
    "            for i in range(473, 473 + 4):\n",
    "                pt = face_landmarks.landmark[i]\n",
    "                x, y = int(pt.x * w), int(pt.y * h)\n",
    "                right_iris_points.append((x, y))\n",
    "                # Draw iris landmarks in red\n",
    "                cv2.circle(frame, (x, y), 2, (0, 0, 255), -1)\n",
    "\n",
    "            # Compute center of the right iris\n",
    "            right_iris_center = (\n",
    "                int(sum([p[0] for p in right_iris_points]) / len(right_iris_points)),\n",
    "                int(sum([p[1] for p in right_iris_points]) / len(right_iris_points))\n",
    "            )\n",
    "\n",
    "            # Draw the estimated iris centers (pupils) in blue\n",
    "            cv2.circle(frame, left_iris_center, 3, (255, 0, 0), -1)\n",
    "            cv2.circle(frame, right_iris_center, 3, (255, 0, 0), -1)\n",
    "\n",
    "    # Show the resulting frame with overlays\n",
    "    cv2.imshow(\"Face Mesh - Eyes and Pupils\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6ab1a",
   "metadata": {},
   "source": [
    "## Face Mesh 3 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66c94bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Capture video from webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resultados = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if resultados.multi_face_landmarks:\n",
    "        for face_landmarks in resultados.multi_face_landmarks:\n",
    "            # Get key points of the eyes\n",
    "            left_eye = face_landmarks.landmark[33]\n",
    "            right_eye = face_landmarks.landmark[263]\n",
    "            \n",
    "            # Convert to absolute coordinates\n",
    "            h, w, _ = frame.shape\n",
    "            left_eye_coords = (int(left_eye.x * w), int(left_eye.y * h))\n",
    "            right_eye_coords = (int(right_eye.x * w), int(right_eye.y * h))\n",
    "\n",
    "            # Calculate the midpoint between the eyes\n",
    "            mid_eye = ((left_eye_coords[0] + right_eye_coords[0]) // 2,\n",
    "                       (left_eye_coords[1] + right_eye_coords[1]) // 2)\n",
    "\n",
    "            # Draw the key points\n",
    "            cv2.circle(frame, left_eye_coords, 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, right_eye_coords, 3, (0, 255, 0), -1)\n",
    "            cv2.circle(frame, mid_eye, 3, (255, 0, 0), -1)  # Midpoint\n",
    "\n",
    "    cv2.imshow(\"Gaze Tracking\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dfa395",
   "metadata": {},
   "source": [
    "## Following the Nose point\n",
    "In the file \"Image Useful\\canonical_face_model_uv_visualization.png\" you can see the different point to locate such the Nose (1) like in the next code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0de36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe Face Mesh (We focus on the face)\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Capture video from the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resultados = face_mesh.process(frame_rgb)\n",
    "\n",
    "    if resultados.multi_face_landmarks:\n",
    "        for face_landmarks in resultados.multi_face_landmarks:\n",
    "            # Get key points of the eyes\n",
    "            Nose = face_landmarks.landmark[1]\n",
    "            \n",
    "            # Convert to absolute coordinates\n",
    "            h, w, _ = frame.shape\n",
    "            Nose_coords = (int(Nose.x * w), int(Nose.y * h))\n",
    "            # Draw the eyes on the image\n",
    "            cv2.circle(frame, Nose_coords, 3, (0, 255, 0), -1)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Face Mesh - Eyes\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
